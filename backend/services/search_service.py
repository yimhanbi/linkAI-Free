
import time
import re
import json
from typing import List, Tuple, Optional

from llama_index.core import VectorStoreIndex, StorageContext, QueryBundle
from llama_index.core.postprocessor import SentenceTransformerRerank
from llama_index.core.response_synthesizers import get_response_synthesizer
from llama_index.core.schema import TextNode, NodeWithScore
from llama_index.core.postprocessor.types import BaseNodePostprocessor

from llama_index.core import Settings
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding

from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, MinShould
from llama_index.vector_stores.qdrant import QdrantVectorStore

import os

#-----------------------------------
#í™˜ê²½ ë³€ìˆ˜
QDRANT_URL = os.getenv("QDRANT_URL")
COLLECTION_NAME = os.getenv("PATENTS_COLLECTION_NAME")
OLLAMA_BASE_URL= os.getenv("OLLAMA_BASE_URL")
LLM_MODEL= os.getenv("OLLAMA_LLM_MODEL")
EMBED_MODEL= os.getenv("OLLAMA_EMBED_MODEL")
RETRIEVER_TOP_K = int(os.getenv("RETRIEVER_TOP_K", "30"))     # ë²¡í„° ê²€ìƒ‰ ìƒìœ„ Kê°œ
RERANKER_TOP_K = int(os.getenv("RERANKER_TOP_K", "6"))       # Reranking í›„ ìƒìœ„ Kê°œ
METADATA_TOP_K = int(os.getenv("METADATA_TOP_K", "10"))      # ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ìƒìš° Kê°œ


#-------------------------------
#ì „ì—­ ë³€ìˆ˜
client:Optional[QdrantClient] = None
index: Optional[VectorStoreIndex]= None
retriever= None
reranker= None
synth= None 


#--------------------------------
#ë¶ˆìš©ì–´ ë° ì¡°ì‚¬ ì •ì˜
#--------------------------------

#ê²€ìƒ‰ ì‹œ ì œì™¸í•  ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ë“¤
STOPWORDS = {
    "í•˜ë‹¤","í•´ì¤˜","ì•Œë ¤ì¤˜","ì°¾ì•„ì¤˜","ê´€ë ¨",
    "íŠ¹í—ˆ","ë°œëª…","ë°œëª…í•œ"
}

# í•œêµ­ì–´ ì¡°ì‚¬ ëª©ë¡ 
JOSA_SUFFIX = (
    "ì€","ëŠ”","ì´","ê°€","ì„","ë¥¼",
    "ì˜","ì—","ì—ì„œ","ìœ¼ë¡œ","ì™€","ê³¼","ë„","ë§Œ"
)


#--------------------------------

class MetaPrefixPostprocessor(BaseNodePostprocessor):
    
    def _postprocess_nodes(
        self,
        nodes: List[NodeWithScore],
        query_str: Optional[str] = None,
    ) -> List[NodeWithScore]:
        
        for nws in nodes:
            node = nws.node
            meta = node.metadata or {}
            
            #ë©”íƒ€ë°ì´í„°ì—ì„œ íŠ¹í—ˆ ì •ë³´ ì¶”ì¶œ
            patent_no = meta.get("patent_no","")
            application_no = meta.get("application_number","")
            title = meta.get("title","")
            
            #ë©”íƒ€ë°ì´í„°ì—ì„œ í”„ë¦¬í”½ìŠ¤ ìƒì„±
            prefix= (
                f"[META]\n"
                f" - ê³µê°œë²ˆí˜¸: {patent_no}\n"
                f" - ì¶œì›ë²ˆí˜¸: {application_no}\n"
                f" - ì œëª©:  {title}\n"
                f"[/META]\n\n"
            )
            
            #ê¸°ì¡´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            orig = getattr(node,"text",None)
            if not orig:
                orig = node.get_content() or ""
            
            #ì´ë¯¸ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            if orig.startswith("[META]\n"):
                node.text= orig
            else:
                node.text = prefix + orig
        
        return nodes 


#--------------------------------------
# í† í°í™” í•¨ìˆ˜
#--------------------------------------
def simple_tokenize_korean(query: str) -> List[str]:
    # 1. í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
    raw_tokens = re.findall(r"[ê°€-í£A-Za-z0-9]+", query)
    cleaned = []
    
    for tok in raw_tokens:
        # 2. ì¡°ì‚¬ ì œê±° (ëì—ì„œë¶€í„° ë§¤ì¹­)
        for josa in JOSA_SUFFIX:
            if tok.endswith(josa) and len(tok) > len(josa):
                tok = tok[:-len(josa)]  # ì¡°ì‚¬ ë¶€ë¶„ ì œê±°
                break
        
        # 3. ë¶ˆìš©ì–´ ë° ì§§ì€ ë‹¨ì–´ ì œê±°
        if tok in STOPWORDS or len(tok) <= 1:
            continue
        
        cleaned.append(tok)
    
    return cleaned


#--------------------------------------
# ë©”íƒ€ë°ì´í„° ê²€ìƒ‰
#--------------------------------------
def qdrant_meta_search(
    tokens: List[str],
    limit: int,
) -> List[NodeWithScore]:
    

    if not tokens:
        return []

    # ê° í† í°ì— ëŒ€í•´ ì—¬ëŸ¬ í•„ë“œì—ì„œ ê²€ìƒ‰ ì¡°ê±´ ìƒì„±
    should_conditions = []
    for t in tokens:
        should_conditions.extend([
            FieldCondition(key="applicants", match=MatchValue(value=t)),        # ì¶œì›ì¸
            FieldCondition(key="inventors", match=MatchValue(value=t)),         # ë°œëª…ì
            FieldCondition(key="agents", match=MatchValue(value=t)),           # ëŒ€ë¦¬ì¸
            FieldCondition(key="patent_no", match=MatchValue(value=t)),        # ê³µê°œë²ˆí˜¸
            FieldCondition(key="application_number", match=MatchValue(value=t)), # ì¶œì›ë²ˆí˜¸
        ])

    # í•„í„° ìƒì„±: sectionì´ "doc_meta"ì´ê³ , ìœ„ ì¡°ê±´ ì¤‘ ìµœì†Œ 1ê°œ ë§Œì¡±
    flt = Filter(
        must=[FieldCondition(key="section", match=MatchValue(value="doc_meta"))],
        min_should=MinShould(conditions=should_conditions, min_count=1),
    )

    # Qdrant ê²€ìƒ‰ ì‹¤í–‰
    hits, _ = client.scroll(
        collection_name=COLLECTION_NAME,
        scroll_filter=flt,
        limit=limit,
        with_payload=True,   # ë©”íƒ€ë°ì´í„° í¬í•¨
        with_vectors=False,  # ë²¡í„°ëŠ” ë¶ˆí•„ìš”
    )

    # ê²°ê³¼ë¥¼ NodeWithScore í˜•íƒœë¡œ ë³€í™˜
    out = []
    for h in hits:
        payload = h.payload or {}
        raw = payload.get("_node_content") or payload.get("text") or ""

        # JSON í˜•íƒœë©´ íŒŒì‹±
        text = raw
        if isinstance(raw, str) and raw.startswith("{"):
            try:
                obj = json.loads(raw)
                text = obj.get("text") or obj.get("_node_content") or raw
            except Exception:
                text = raw

        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (text, _node_content ì œì™¸)
        meta = {k: v for k, v in payload.items() if k not in ("text", "_node_content")}
        
        # TextNode ìƒì„±
        node = TextNode(text=text, metadata=meta)
        out.append(NodeWithScore(node=node, score=0.0))
    
    return out


#--------------------------------------
# ì¶œì²˜ ì¶”ì¶œ
#--------------------------------------
def print_sources(nodes: List[NodeWithScore]) -> List[dict]:
    """
     combined_nodesì—ì„œ ì¶œì²˜(ê³µê°œë²ˆí˜¸, ì¶œì›ë²ˆí˜¸, ì œëª©)ë¥¼
    ì¤‘ë³µ ì œê±°í•´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥
    """
    
    seen = set()  # ì¤‘ë³µ ì²´í¬ìš©
    results = []

    for nws in nodes:
        meta = nws.node.metadata or {}
        patent_no = meta.get("patent_no")
        application_no = meta.get("application_number")
        title = meta.get("title")

        # ì •ë³´ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if not (patent_no or application_no or title):
            continue

        # ì¤‘ë³µ ì²´í¬ (ì„¸ í•„ë“œ ì¡°í•©ìœ¼ë¡œ íŒë‹¨)
        key = (patent_no, application_no, title)
        if key in seen:
            continue

        seen.add(key)
        results.append(key)
        
        
    if not results:
        print("\n===ì¶œì²˜ ===\nì—†ìŒ")
    return results


    print("\n=== ì¶œì²˜ ===\n")
    for i, (pno, ano, title) in enumerate(results, 1):
        print(f"[{i}] ê³µê°œë²ˆí˜¸: {pno}")
        print(f"    ì¶œì›ë²ˆí˜¸: {ano}")
        print(f"    íŠ¹í—ˆì œëª©: {title}")
        print()





#--------------------------------------
# ì´ˆê¸°í™” í•¨ìˆ˜
#--------------------------------------
async def initialize_llamaindex():
    global client, index, retriever, reranker, synth
    
    # 1. ì‹œì‘ ì‹œê°„ ê¸°ë¡ (ì—ëŸ¬ ë°©ì§€ í•µì‹¬!)
    start = time.time()
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    openai_key = os.getenv("OPENAI_API_KEY")
    llm_name = "gpt-4o-mini" if openai_key else LLM_MODEL
    print(f"â–¶ Initializing LlamaIndex with {llm_name}...")
    
    try:
        # 2. LLM ì„¤ì •
        if openai_key:
            from llama_index.llms.openai import OpenAI
            os.environ["OPENAI_API_KEY"] = openai_key
            Settings.llm = OpenAI(model="gpt-4o-mini")
            print("ğŸš€ LLM Mode: OpenAI (gpt-4o-mini)")
        else:
            Settings.llm = Ollama(
                model=LLM_MODEL,
                base_url=OLLAMA_BASE_URL,
                request_timeout=300.0 
            )
            print(f"ğŸ  LLM Mode: Ollama ({LLM_MODEL})")

        # 3. Embedding ì„¤ì •
        Settings.embed_model = OllamaEmbedding(
            model_name=EMBED_MODEL,
            base_url=OLLAMA_BASE_URL
        )
# async def initialize_llamaindex():
#     global client, index, retriever, reranker, synth
    
#     start = time.time()
#     print(f"â–¶ Initializing LlamaIndex with Ollama ({LLM_MODEL})...")
    
    
#     try:
#         #Ollama ëª¨ë¸ LlamaIndex ì „ì—­ ì„¤ì •ì— ì£¼ì… --
#         #1. LLM ì„¤ì • (ë‹µë³€ ìƒì„±ìš©)
#         Settings.llm = Ollama(
#             model = LLM_MODEL,
#             base_url = OLLAMA_BASE_URL,
#             request_timeout=600.0,
#         )
        
#         #2. Embedding ì„¤ì • 
#         Settings.embed_model = OllamaEmbedding(
#             model_name = EMBED_MODEL,
#             base_url = OLLAMA_BASE_URL,
#             request_timeout=900.0,
#         )
        
        # --------------------------------------------------
        
       # 4. Qdrant í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
        client = QdrantClient(url=QDRANT_URL, timeout=60)
        print("â–¶ Qdrant Connected")
        
        # 5. Vector Store & Index ìƒì„±
        vector_store = QdrantVectorStore(client=client, collection_name=COLLECTION_NAME)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        
        index = VectorStoreIndex.from_vector_store(
            vector_store=vector_store,
            storage_context=storage_context,
        )
        
        # 6. ê²€ìƒ‰ ë° ì—”ì§„ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
        retriever = index.as_retriever(similarity_top_k=RETRIEVER_TOP_K)
        
        reranker = SentenceTransformerRerank(
            model="cross-encoder/ms-marco-MiniLM-L-6-v2",
            top_n=RERANKER_TOP_K
            # device = "cpu"
        )
        
        synth = get_response_synthesizer(
            response_mode="compact"
        )
        
        # 7. ì†Œìš” ì‹œê°„ ê³„ì‚°
        elapsed = time.time() - start
        print(f"âœ… LlamaIndex engine initialized in {elapsed:.2f}ì´ˆ")
        
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise e
    


#--------------------------------------
# ì¿¼ë¦¬ ì‹¤í–‰ í•¨ìˆ˜
#--------------------------------------
async def run_llamaindex_query(query: str, top_k: int = 30) -> Tuple[str, List[dict]]:
    overall_start = time.time()
    
    print(f"\n{'#'*70}")
    print(f"ğŸ” [LlamaIndex RAG ì‹œì‘] Query: '{query}'")
    print(f"{'#'*70}")
    
    try:
        # 1. ì¿¼ë¦¬ ë²ˆë“¤ ìƒì„±
        qb = QueryBundle(query)
        
        # 2. ë²¡í„° ê²€ìƒ‰
        retrieve_start = time.time()
        base_nodes = retriever.retrieve(qb)
        retrieve_elapsed = time.time() - retrieve_start
        print(f"â±ï¸  [1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰] {retrieve_elapsed:.2f}ì´ˆ â†’ {len(base_nodes)}ê°œ ë…¸ë“œ")
        
        # 3. Reranking
        rerank_start = time.time()
        reranked_nodes = reranker.postprocess_nodes(base_nodes, query_bundle=qb)
        rerank_elapsed = time.time() - rerank_start
        print(f"â±ï¸  [2ë‹¨ê³„: Reranking] {rerank_elapsed:.2f}ì´ˆ â†’ {len(reranked_nodes)}ê°œ ë…¸ë“œ")
        
        # 4. ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ (ê°€ì¥ ì˜ì‹¬ë˜ëŠ” êµ¬ê°„ 1)
        meta_start = time.time()
        tokens = simple_tokenize_korean(query)
        print(f"ğŸ” [í† í°í™” ì™„ë£Œ] {tokens}")
        
        # qdrant_meta_search ë‚´ë¶€ì—ì„œ ì—ëŸ¬ê°€ ë‚˜ëŠ”ì§€ í™•ì¸
        meta_nodes = qdrant_meta_search(tokens=tokens, limit=METADATA_TOP_K)
        meta_elapsed = time.time() - meta_start
        print(f"â±ï¸  [3ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ê²€ìƒ‰] {meta_elapsed:.2f}ì´ˆ â†’ {len(meta_nodes)}ê°œ ë…¸ë“œ")
        
        # 5. ë…¸ë“œ ê²°í•© ë° í”„ë¦¬í”½ìŠ¤ ì¶”ê°€
        combine_start = time.time()
        combined_nodes = list(reranked_nodes) + list(meta_nodes)
        
        postprocessor = MetaPrefixPostprocessor()
        combined_nodes = postprocessor.postprocess_nodes(combined_nodes, query_str=query)
        combine_elapsed = time.time() - combine_start
        print(f"â±ï¸  [4ë‹¨ê³„: ë…¸ë“œ ê²°í•©] {combine_elapsed:.2f}ì´ˆ")
        
        # 6. LLM ë‹µë³€ ìƒì„± (ê°€ì¥ ì˜ì‹¬ë˜ëŠ” êµ¬ê°„ 2 - OpenAI í˜¸ì¶œ)
        llm_start = time.time()
        print(f"ğŸ§  [5ë‹¨ê³„: LLM ë‹µë³€ ìƒì„± ì¤‘...]")
        
        # ì—¬ê¸°ì„œ ë©ˆì¶˜ë‹¤ë©´ API í‚¤ ë¬¸ì œë‚˜ ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì…ë‹ˆë‹¤.
        resp = synth.synthesize(qb, combined_nodes)
        answer = str(resp)
        
        llm_elapsed = time.time() - llm_start
        print(f"â±ï¸  [5ë‹¨ê³„: LLM ë‹µë³€] {llm_elapsed:.2f}ì´ˆ")
        
        # 7. ì¶œì²˜ ì¶”ì¶œ
        sources = print_sources(combined_nodes)
        overall_elapsed = time.time() - overall_start
        print(f"âœ… [ì „ì²´ ì™„ë£Œ] {overall_elapsed:.2f}ì´ˆ\n")
        
        return answer, sources

    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ë¡œê·¸ë¥¼ í„°ë¯¸ë„ì— ê°•ì œë¡œ ì°ìŠµë‹ˆë‹¤.
        print("\n" + "!"*30 + " ERROR ë°œìƒ " + "!"*30)
        import traceback
        traceback.print_exc() # ì–´ëŠ ì¤„ì—ì„œ ì—ëŸ¬ê°€ ë‚¬ëŠ”ì§€ ì•Œë ¤ì¤Œ
        print("!"*72 + "\n")
        # ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë˜ì ¸ì„œ 500 ì‘ë‹µì´ ë‚˜ê°€ê²Œ í•¨
        raise e


    
# ìˆ˜ì • í›„ (ë°©ì–´ ì½”ë“œ ì ìš©)
async def close(self):
    # hasattrë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ë‹«ìŠµë‹ˆë‹¤.
    if hasattr(self, 'client_openai_async') and self.client_openai_async:
        await self.client_openai_async.close()
    
    # Qdrant í´ë¼ì´ì–¸íŠ¸ ë“± ë‹¤ë¥¸ ì—°ê²°ë„ ì•ˆì „í•˜ê²Œ ë‹«ê¸°
    if hasattr(self, 'client') and self.client:
        self.client.close()
        
    print("âœ… ì±—ë´‡ ê²€ìƒ‰ ì„œë¹„ìŠ¤ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    